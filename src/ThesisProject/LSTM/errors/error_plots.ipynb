{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from src.GLOBAL_VARS import NotTrustedPlants\n",
    "\n",
    "model_dir = 'model'\n",
    "\n",
    "df = pd.read_csv(f'{model_dir}/all_errors.csv')\n",
    "\n",
    "df = df[df['forecast_horizon'] == 24]\n",
    "# df = df.drop(columns=['MAPE']) # used if horizon==1\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "wf_id_list = df[df['wf_id'].isin(NotTrustedPlants)]['wf_id'].unique()\n",
    "print(wf_id_list)\n",
    "\n",
    "df = df[~df['wf_id'].isin(NotTrustedPlants)]\n",
    "df = df[~df['wf_id'].isin([47, 49, 89, 154, 196])]\n",
    "\n",
    "\n",
    "df = df[(df['time_steps'] == 1) |\n",
    "        (df['time_steps'] == 2) |\n",
    "        (df['time_steps'] == 4) |\n",
    "        (df['time_steps'] == 8)\n",
    "]\n",
    "df = df[(df['number_of_cells'] == (\"[64, 32, 16]\")) |\n",
    "        (df['number_of_cells'] == (\"[128, 64, 32]\")) |\n",
    "        (df['number_of_cells'] == (\"[256, 128, 64]\")) |\n",
    "        (df['number_of_cells'] == (\"[512, 256, 128]\"))\n",
    "]\n",
    "df = df[(df['batch_size'] == 32) |\n",
    "        (df['batch_size'] == 64) |\n",
    "        (df['batch_size'] == 128)\n",
    "]\n",
    "df = df[df['epochs'] == 100]\n",
    "df = df[(df['learning_rate'] == 0.001) |\n",
    "        (df['learning_rate'] == 0.01)\n",
    "]\n",
    "df = df[df['dropout_rate'] == 0.2]\n",
    "\n",
    "selected_hyperparameters = df\n",
    "selected_hyperparameters"
   ],
   "id": "55eac7c01b7d8a47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_r2 = pd.DataFrame()\n",
    "# for every wf_id in the df, get the top 100 best r^2 values\n",
    "for wf_id in selected_hyperparameters['wf_id'].unique():\n",
    "    # get the top 100 best r^2 values\n",
    "    df_wf_id = df[df['wf_id'] == wf_id]\n",
    "    df_wf_id = df_wf_id.sort_values(by=['nMAE_overall'], ascending=True) # NOT R2 (asc=false) RIGHT NOW!!!!!!!!!!!!!!!\n",
    "    df_wf_id = df_wf_id.head(5)\n",
    "\n",
    "    best_r2 = pd.concat([best_r2, df_wf_id], ignore_index=True)\n",
    "\n",
    "#best_r2 = best_r2[best_r2['wf_id'] != 154]\n",
    "best_r2.to_csv('{}/all_errors_bests.csv'.format(model_dir), index=False)\n",
    "best_r2"
   ],
   "id": "7e9bb8db44b3759d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_hyperparameters_by_farm_count(df):\n",
    "    \"\"\"\n",
    "    Finds unique hyperparameter combinations from the input DataFrame and\n",
    "    counts how many distinct wind farms (wf_id) each combination is\n",
    "    associated with. The results are sorted by this count in descending order.\n",
    "\n",
    "    It is assumed that the input DataFrame 'df' only contains hyperparameter\n",
    "    combinations that have already yielded \"pretty good\" results for each\n",
    "    respective wind farm.\n",
    "    \"\"\"\n",
    "    hyperparameter_cols = [\n",
    "        'time_steps',\n",
    "        'learning_rate',\n",
    "        'epochs',\n",
    "        'batch_size',\n",
    "        'number_of_cells',\n",
    "        'dropout_rate'\n",
    "    ]\n",
    "\n",
    "    # --- Input Validation ---\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Error: Input must be a pandas DataFrame.\")\n",
    "        return []\n",
    "    if df.empty:\n",
    "        print(\"Input DataFrame is empty. No analysis can be performed.\")\n",
    "        return []\n",
    "\n",
    "    required_cols = hyperparameter_cols + ['wf_id']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Error: DataFrame is missing required columns: {', '.join(missing_cols)}\")\n",
    "        return []\n",
    "\n",
    "    # --- Core Logic ---\n",
    "    try:\n",
    "        # Group by the hyperparameter columns and for each group, count the number of unique wf_ids.\n",
    "        # This tells us for each unique hyperparameter combination, how many distinct wind farms it was used for.\n",
    "        farm_counts_per_combo = df.groupby(hyperparameter_cols)['wf_id'].nunique()\n",
    "\n",
    "        # Sort these combinations by the number of wind farms (the counts) in descending order.\n",
    "        sorted_farm_counts = farm_counts_per_combo.sort_values(ascending=False)\n",
    "\n",
    "        # Convert the sorted Series into a list of tuples for easier handling and presentation.\n",
    "        # Each item in the list will be: ( (hyperparam_val1, hp_val2, ...), farm_count )\n",
    "        result_list = []\n",
    "        for hyperparam_tuple, count in sorted_farm_counts.items():\n",
    "            result_list.append((hyperparam_tuple, count))\n",
    "\n",
    "        return result_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during analysis: {e}\")\n",
    "        return []\n",
    "\n",
    "best_r2_df = best_r2\n",
    "\n",
    "print(\"--- Analyzing best_r2_df ---\")\n",
    "ranked_hyperparameters = find_hyperparameters_by_farm_count(best_r2_df)\n",
    "\n",
    "if ranked_hyperparameters:\n",
    "    print(\"\\nHyperparameter combinations sorted by the number of wind farms they apply to (most farms first):\")\n",
    "    param_names = [\n",
    "        'Time Steps', 'Learning Rate', 'Epochs', 'Batch Size',\n",
    "        'Number of Cells', 'Dropout Rate'\n",
    "    ]\n",
    "    for hp_tuple, count in ranked_hyperparameters:\n",
    "        print(f\"\\nShared by {count} wind farm(s):\")\n",
    "        for name, value in zip(param_names, hp_tuple):\n",
    "            print(f\"  {name}: {value}\")\n",
    "elif not best_r2_df.empty: # If list is empty but df wasn't, an error message was already printed\n",
    "    print(\"No results to display. Check for earlier error messages if data was provided.\")\n",
    "# If best_r2_df was empty, a message is already printed by the function.\n",
    "\n",
    "# total 15 left"
   ],
   "id": "56910505b9c1794",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def create_file_name(row):\n",
    "    \"\"\"\n",
    "    Creates a standardized file name from a row of the errors DataFrame based on\n",
    "    the specified project naming convention.\n",
    "\n",
    "    This function correctly parses list-like strings for 'number_of_cells'\n",
    "    and 'variables' into the required format.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from the errors DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated file name string.\n",
    "    \"\"\"\n",
    "    # --- Handle 'number_of_cells' ---\n",
    "    # Parses string like '[64, 32, 16]' into '64_32_16'\n",
    "    try:\n",
    "        cells_list = ast.literal_eval(str(row['number_of_cells']))\n",
    "        cells_str = \"_\".join(map(str, cells_list))\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Fallback for any variations in format\n",
    "        cells_str = str(row['number_of_cells']).strip(\"[]\").replace(\", \", \"_\").replace(\",\", \"_\")\n",
    "\n",
    "    # --- Handle 'variables' ---\n",
    "    # Parses string like \"['u100', 'v100']\" into 'u100-v100'\n",
    "    try:\n",
    "        vars_list = ast.literal_eval(str(row['variables']))\n",
    "        vars_str = \"-\".join(vars_list)\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Fallback for unexpected formats\n",
    "        vars_str = str(row['variables']).strip(\"[]'\").replace(\"', '\", \"-\").replace(\"'\", \"\")\n",
    "\n",
    "    # --- Construct the final file name ---\n",
    "    file_name = (\n",
    "        f\"LSTM_wf{row['wf_id']}\"\n",
    "        f\"_start{row['start_date']}\"\n",
    "        f\"_end{row['end_date']}\"\n",
    "        f\"_filt{row['filter_data']}\"\n",
    "        f\"_lag{row['production_lag']}\"\n",
    "        f\"_steps{row['time_steps']}\"\n",
    "        f\"_bs{row['batch_size']}\"\n",
    "        f\"_ep{row['epochs']}\"\n",
    "        f\"_do{row['dropout_rate']}\"\n",
    "        f\"_lr{row['learning_rate']}\"\n",
    "        f\"_cells[{cells_str}]\"\n",
    "        f\"_vars[{vars_str}]\"\n",
    "        f\"_dense{row['dense']}\"\n",
    "    )\n",
    "\n",
    "    return file_name"
   ],
   "id": "53f16b902e2ccbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get the data for each wind farm with the following parameters\n",
    "#   Time Steps: 4\n",
    "#   Learning Rate: 0.001\n",
    "#   Epochs: 100\n",
    "#   Batch Size: 128\n",
    "#   Number of Cells: [256, 128, 64]\n",
    "#   Dropout Rate: 0.2\n",
    "\n",
    "import pandas as pd\n",
    "from src.GLOBAL_VARS import NotTrustedPlants\n",
    "\n",
    "model_dir = 'model'\n",
    "\n",
    "df = pd.read_csv(f'{model_dir}/all_errors.csv')\n",
    "\n",
    "df = df[df['forecast_horizon'] == 24]\n",
    "# df = df.drop(columns=['MAPE']) # used if horizon==1\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "\n",
    "df = df[~df['wf_id'].isin(NotTrustedPlants)]\n",
    "df = df[~df['wf_id'].isin([45, 47, 49, 89, 154, 196])]\n",
    "\n",
    "\n",
    "df = df[((df['time_steps'] == 4))]\n",
    "df = df[(df['number_of_cells'] == (\"[256, 128, 64]\"))]\n",
    "df = df[(df['batch_size'] == 128)]\n",
    "df = df[df['epochs'] == 100]\n",
    "df = df[(df['learning_rate'] == 0.001)]\n",
    "df = df[df['dropout_rate'] == 0.2]\n",
    "\n",
    "best_config_models = df\n",
    "best_config_models\n"
   ],
   "id": "fd263dc37e4a4136",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load Data and Define Models to Analyze ---\n",
    "# This cell assumes the 'best_r2' DataFrame has been created in a previous cell.\n",
    "best_r2_df = best_config_models\n",
    "\n",
    "# --- 2. Iterate Through Models and Collect Metrics ---\n",
    "# NOTE: The path is hardcoded as in your example.\n",
    "model_dir = '/mnt/chromeos/GoogleDrive/MyDrive/Education/University/Non-ESE Courses/Misc./Wind Turbines Project/WFP/src/ThesisProject/LSTM/model'\n",
    "\n",
    "# Define all possible horizons to initialize the metrics dictionary\n",
    "metrics_by_horizon = {h: {'nMAE': [], 'nRMSE': [], 'R^2': []} for h in range(1, 25)}\n",
    "\n",
    "for _, row in best_r2_df.iterrows():\n",
    "    # create_file_name() is assumed to be defined in a previous cell\n",
    "    folder_name = create_file_name(row)\n",
    "    model_folder_path = os.path.join(model_dir, folder_name)\n",
    "\n",
    "    # A single model run produces one error file containing all horizons.\n",
    "    # The filename contains the max horizon, which is in the 'forecast_horizon' column.\n",
    "    error_file_path = os.path.join(model_folder_path, f\"errors_{row['prediction_method']}_{row['forecast_horizon']}.txt\")\n",
    "\n",
    "    if os.path.exists(error_file_path):\n",
    "        try:\n",
    "            with open(error_file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            metric_key_map = {\n",
    "                'nMAE_capacity': 'nMAE',\n",
    "                'nRMSE_capacity': 'nRMSE',\n",
    "                'R^2': 'R^2'\n",
    "            }\n",
    "\n",
    "            for line in lines:\n",
    "                # CORRECTED REGEX: Removed the erroneous backslash from `\\e`.\n",
    "                match = re.search(r\"^(nMAE_capacity|nRMSE_capacity|R\\^2)_t\\+(\\d+):\\s*([\\d\\.e\\+\\-]+|nan)\", line)\n",
    "\n",
    "                if match:\n",
    "                    file_metric_key, horizon_str, value_str = match.groups()\n",
    "\n",
    "                    if file_metric_key in metric_key_map:\n",
    "                        metric_name = metric_key_map[file_metric_key]\n",
    "                        horizon = int(horizon_str)\n",
    "\n",
    "                        if horizon in metrics_by_horizon:\n",
    "                            try:\n",
    "                                value = float(value_str)\n",
    "                                metrics_by_horizon[horizon][metric_name].append(value)\n",
    "                            except ValueError:\n",
    "                                metrics_by_horizon[horizon][metric_name].append(np.nan)\n",
    "        except Exception as e:\n",
    "            # This will now correctly report other errors, if any.\n",
    "            print(f\"Warning: Could not process file: {error_file_path}. Error: {e}\")\n",
    "\n",
    "# --- 3. Calculate Average Metrics ---\n",
    "avg_metrics = {m: [] for m in ['nMAE', 'nRMSE', 'R^2']}\n",
    "sorted_horizons = sorted(metrics_by_horizon.keys())\n",
    "\n",
    "for horizon in sorted_horizons:\n",
    "    for metric in avg_metrics.keys():\n",
    "        values = [v for v in metrics_by_horizon[horizon][metric] if v is not None and not np.isnan(v)]\n",
    "        if values:\n",
    "            avg_metrics[metric].append(np.mean(values))\n",
    "        else:\n",
    "            avg_metrics[metric].append(np.nan)"
   ],
   "id": "a534d87d9bbddc6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# --- 4. Create the Plot (Refined Version) ---\n",
    "\n",
    "# Create figure with specified size and DPI\n",
    "fig, ax1 = plt.subplots(figsize=(12, 8), dpi=100)\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Define professional-looking colors\n",
    "color_nmae = '#003366'  # Dark blue\n",
    "color_nrmse = '#3399FF' # Lighter blue\n",
    "color_r2 = '#CC3300'    # Deep red/orange\n",
    "\n",
    "# Plot nMAE and nRMSE on the primary y-axis (ax1)\n",
    "ax1.set_xlabel('Forecast Horizon (hours)', fontsize=14)\n",
    "ax1.set_ylabel('Normalized Error (nMAE, nRMSE)', color=color_nmae, fontsize=14)\n",
    "line1 = ax1.plot(sorted_horizons, avg_metrics['nMAE'], marker='o', linestyle='-', color=color_nmae, label='Average nMAE')\n",
    "line2 = ax1.plot(sorted_horizons, avg_metrics['nRMSE'], marker='s', linestyle='--', color=color_nrmse, label='Average nRMSE')\n",
    "ax1.tick_params(axis='y', labelcolor=color_nmae)\n",
    "ax1.set_facecolor('none')\n",
    "\n",
    "# Create a second y-axis for R^2 (ax2)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('R² Score', color=color_r2, fontsize=14)\n",
    "line3 = ax2.plot(sorted_horizons, avg_metrics['R^2'], marker='^', linestyle=':', color=color_r2, label='Average R²')\n",
    "ax2.tick_params(axis='y', labelcolor=color_r2)\n",
    "ax2.set_facecolor('none')\n",
    "\n",
    "# Align Y-axis ticks to have the same number of \"round\"-valued grid lines\n",
    "# MaxNLocator automatically finds nice, round numbers for the tick marks.\n",
    "ax1.yaxis.set_major_locator(MaxNLocator(nbins=6, prune='both'))\n",
    "ax2.yaxis.set_major_locator(MaxNLocator(nbins=6, prune='both'))\n",
    "\n",
    "# Add a light, non-intrusive grid that now aligns perfectly\n",
    "ax1.grid(True, which='major', linestyle='--', linewidth=0.5, color='gray', alpha=0.6)\n",
    "\n",
    "# Hide top spines for a cleaner look\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "\n",
    "# Set title\n",
    "plt.title('Average Model Performance vs. Forecast Horizon', fontsize=16, y=1.08)\n",
    "\n",
    "# --- UPDATED: Combine legends and place on top ---\n",
    "lines = line1 + line2 + line3\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels,\n",
    "           loc='lower center',             # Anchor point of the legend box\n",
    "           bbox_to_anchor=(0.5, 1.02),      # Position the anchor point\n",
    "           ncol=3,                         # Arrange legend items horizontally\n",
    "           frameon=True,\n",
    "           fontsize=12)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.xticks(sorted_horizons)\n",
    "plt.savefig('plots_for_thesis/Performance_vs_Horizon.png', dpi=100)\n",
    "plt.show()\n",
    "\n",
    "# Reset matplotlib settings to default if you have other plots in the notebook\n",
    "plt.rcdefaults()"
   ],
   "id": "86779291c851322e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Restructure Data for Box Plotting ---\n",
    "# This cell assumes the 'metrics_by_horizon' dictionary is already populated.\n",
    "# We convert it to a long-form DataFrame ideal for Seaborn.\n",
    "\n",
    "plot_data = []\n",
    "sorted_horizons = sorted(metrics_by_horizon.keys())\n",
    "\n",
    "for horizon in sorted_horizons:\n",
    "    if not metrics_by_horizon[horizon]['nMAE']:\n",
    "        continue\n",
    "\n",
    "    for metric_name, values in metrics_by_horizon[horizon].items():\n",
    "        for value in values:\n",
    "            if value is not None and not np.isnan(value):\n",
    "                plot_data.append({\n",
    "                    'Horizon': horizon,\n",
    "                    'Metric': metric_name,\n",
    "                    'Value': value\n",
    "                })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "\n",
    "# --- 2. Create the Box Plots with Averages ---\n",
    "plt.style.use('default')\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 12), sharex=True, dpi=100)\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Define properties for the mean marker\n",
    "mean_props = {\n",
    "    \"marker\": \"o\",\n",
    "    \"markerfacecolor\": \"white\",\n",
    "    \"markeredgecolor\": \"black\",\n",
    "    \"markersize\": \"8\"\n",
    "}\n",
    "\n",
    "# --- Top Subplot: nMAE and nRMSE Distributions ---\n",
    "ax_top = axes[0]\n",
    "sns.boxplot(x='Horizon', y='Value', hue='Metric',\n",
    "            data=plot_df[plot_df['Metric'].isin(['nMAE', 'nRMSE'])],\n",
    "            ax=ax_top,\n",
    "            palette={'nMAE': '#003366', 'nRMSE': '#3399FF'},\n",
    "            showmeans=True,      # This tells seaborn to show the mean\n",
    "            meanprops=mean_props # This styles the mean marker\n",
    "           )\n",
    "ax_top.set_title('Distribution of Normalized Errors vs. Forecast Horizon', fontsize=16)\n",
    "ax_top.set_ylabel('Normalized Error Value', fontsize=12)\n",
    "ax_top.set_xlabel('')\n",
    "ax_top.legend(title='Metric')\n",
    "ax_top.grid(True, which='major', axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "\n",
    "# --- Bottom Subplot: R^2 Distribution ---\n",
    "ax_bottom = axes[1]\n",
    "sns.boxplot(x='Horizon', y='Value',\n",
    "            data=plot_df[plot_df['Metric'] == 'R^2'],\n",
    "            ax=ax_bottom,\n",
    "            color='#CC3300',\n",
    "            showmeans=True,      # Show the mean here as well\n",
    "            meanprops=mean_props\n",
    "           )\n",
    "ax_bottom.set_title('Distribution of R² Score vs. Forecast Horizon', fontsize=16)\n",
    "ax_bottom.set_ylabel('R² Score', fontsize=12)\n",
    "ax_bottom.set_xlabel('Forecast Horizon (hours)', fontsize=14)\n",
    "ax_bottom.grid(True, which='major', axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "\n",
    "# Final adjustments\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "plt.savefig('plots_for_thesis/Box_Plot_Horizons.png', dpi=100)\n",
    "plt.show()"
   ],
   "id": "b2be94b9d837a193",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import io\n",
    "\n",
    "# --- Helper Function to Load Data ---\n",
    "def load_3d_from_txt(file_path):\n",
    "    \"\"\"\n",
    "    Loads a 3D NumPy array that was saved slice-by-slice into a text file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the text file.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The reconstructed 3D NumPy array.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Extract the original shape from the header comment\n",
    "    shape_match = re.search(r'# Array shape: \\((.*?)\\)', content)\n",
    "    if not shape_match:\n",
    "        raise ValueError(\"Could not find array shape in file header.\")\n",
    "    shape = tuple(map(int, shape_match.group(1).split(',')))\n",
    "\n",
    "    # Split the file content by the slice separator\n",
    "    # We remove the header part before splitting\n",
    "    header = \"# Array shape: {0}\\n\".format(shape)\n",
    "    data_content = content.replace(header, '')\n",
    "\n",
    "    # Use a robust text block parser\n",
    "    slices_str = data_content.split('# New slice\\n')\n",
    "\n",
    "    loaded_slices = []\n",
    "    for s in slices_str:\n",
    "        s_clean = s.strip()\n",
    "        if s_clean: # Ensure the slice is not empty\n",
    "            try:\n",
    "                # Use numpy's loadtxt on the string block\n",
    "                slice_arr = np.loadtxt(io.StringIO(s_clean))\n",
    "                # Reshape if it's a single column vector\n",
    "                if len(slice_arr.shape) == 1:\n",
    "                    slice_arr = slice_arr.reshape(-1, 1)\n",
    "                loaded_slices.append(slice_arr)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping a malformed slice. Error: {e}\")\n",
    "\n",
    "    # Stack the 2D slices to form a 3D array\n",
    "    if not loaded_slices:\n",
    "        raise ValueError(\"No data slices were loaded from the file.\")\n",
    "\n",
    "    array_3d = np.stack(loaded_slices, axis=0)\n",
    "\n",
    "    # Verify final shape\n",
    "    if array_3d.shape != shape:\n",
    "        print(f\"Warning: Reconstructed shape {array_3d.shape} does not match header shape {shape}. Reshaping...\")\n",
    "        array_3d = array_3d.reshape(shape)\n",
    "\n",
    "    return array_3d"
   ],
   "id": "f4adf8da41fbea7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# --- Configuration for the Plot ---\n",
    "model_investigate_dir = '../model_investigate'\n",
    "\n",
    "### AR vs SS models\n",
    "# folder_name = 'LSTM_wf9_start2020-01-01_end2023-12-31_filtFalse_lag1_steps16_bs32_ep100_do0.4_lr0.01_cells[128_64_32]_vars[u100-v100-air_density]_dense1'\n",
    "# folder_name = 'LSTM_wf9_start2020-01-01_end2023-12-31_filtFalse_lag1_steps16_bs32_ep500_do0.4_lr0.01_cells[512_128_64]_vars[u100-v100-air_density]_dense24'\n",
    "\n",
    "### Best model's plots\n",
    "folder_name = 'LSTM_wf58_start2020-01-01_end2023-12-31_filtFalse_lag1_steps4_bs64_ep100_do0.2_lr0.001_cells[256_128_64]_vars[u100-v100-air_density]_dense1'\n",
    "\n",
    "\n",
    "# --- Automatic Discovery of Files and Parameters ---\n",
    "try:\n",
    "    investigation_path = os.path.join(model_investigate_dir, folder_name)\n",
    "    pred_pattern = re.compile(r\"y_pred_(single_shot|autoregressive|autoregressive_attention)_(\\d+)\\.txt\")\n",
    "\n",
    "    y_pred_filename, prediction_method_raw, prediction_method, forecast_horizon = None, None, None, None\n",
    "\n",
    "    for filename in os.listdir(investigation_path):\n",
    "        match = pred_pattern.match(filename)\n",
    "        if match:\n",
    "            y_pred_filename = filename\n",
    "            prediction_method_raw = match.group(1)\n",
    "            prediction_method = prediction_method_raw.replace('_', ' ').title()\n",
    "            forecast_horizon = int(match.group(2))\n",
    "            # Define all corresponding filenames\n",
    "            y_true_filename = f\"y_true_{prediction_method_raw}_{forecast_horizon}.txt\"\n",
    "            x_test_filename = f\"x_test_{prediction_method_raw}_{forecast_horizon}.txt\"\n",
    "            break\n",
    "\n",
    "    if not y_pred_filename:\n",
    "        raise FileNotFoundError(f\"Could not find a y_pred_* file in '{investigation_path}'\")\n",
    "\n",
    "    steps_match = re.search(r'_steps(\\d+)_', folder_name)\n",
    "    if not steps_match:\n",
    "        raise ValueError(f\"Could not extract time_steps from folder name: {folder_name}\")\n",
    "    time_steps = int(steps_match.group(1))\n",
    "\n",
    "    print(f\"Discovered files for '{prediction_method}' method.\")\n",
    "    print(f\"Forecast Horizon: {forecast_horizon}, Input Time Steps: {time_steps}\")\n",
    "\n",
    "    # --- Load the Data (including X_test) ---\n",
    "    y_true_path = os.path.join(investigation_path, y_true_filename)\n",
    "    y_pred_path = os.path.join(investigation_path, y_pred_filename)\n",
    "    x_test_path = os.path.join(investigation_path, x_test_filename)\n",
    "\n",
    "    # Assumes load_3d_from_txt is defined in a previous cell\n",
    "    y_true = load_3d_from_txt(y_true_path)\n",
    "    y_pred = load_3d_from_txt(y_pred_path)\n",
    "    X_test = load_3d_from_txt(x_test_path)\n",
    "\n",
    "    print(f\"Successfully loaded y_true with shape: {y_true.shape}\")\n",
    "    print(f\"Successfully loaded y_pred with shape: {y_pred.shape}\")\n",
    "    print(f\"Successfully loaded X_test with shape: {X_test.shape}\")\n",
    "    data_loaded = True\n",
    "\n",
    "except (FileNotFoundError, ValueError, NameError) as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Please ensure 'folder_name' is correct and 'load_3d_from_txt' is defined.\")\n",
    "    data_loaded = False"
   ],
   "id": "2fecbe54169025fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# --- Plotting the Time Series Comparison ---\n",
    "if data_loaded:\n",
    "    num_samples = y_true.shape[0]\n",
    "    time_index = np.arange(num_samples) + time_steps\n",
    "    color_actual = '#003366'\n",
    "    color_pred = '#CC3300'\n",
    "\n",
    "    if forecast_horizon == 1:\n",
    "        # This part remains the same for single-step forecasts\n",
    "        fig, ax = plt.subplots(figsize=(14, 7), dpi=100)\n",
    "        fig.patch.set_facecolor('white')\n",
    "        ax.plot(time_index, y_true[:, 0, 0], label='Actual', color=color_actual)\n",
    "        ax.plot(time_index, y_pred[:, 0, 0], label='Predicted', color=color_pred, linewidth=0.8, alpha=0.9)\n",
    "        ax.set_xlabel('Complete Sample Data Length)', fontsize=12)\n",
    "        ax.set_ylabel('Production', fontsize=12)\n",
    "        ax.set_title(f'Time Series: Actual vs. Predicted ({prediction_method})', fontsize=16)\n",
    "        ax.legend(frameon=True, edgecolor='black')\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        plt.tight_layout()\n",
    "        output_path = os.path.join('plots_for_thesis', f'time_series_{prediction_method_raw}_{forecast_horizon}.png')\n",
    "        plt.savefig(output_path)\n",
    "        print(f\"Plot saved to: {output_path}\")\n",
    "        plt.show()\n",
    "\n",
    "    else: # --- MODIFIED: Multi-step forecast plotting in groups of 4 ---\n",
    "        group_size = 4\n",
    "        for group_index, start_h in enumerate(range(0, forecast_horizon, group_size)):\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(16, 10), sharex=True, dpi=100, facecolor='white')\n",
    "            fig.suptitle(f'Time Series: Actual vs. Predicted ({prediction_method})', fontsize=20)\n",
    "            axes = axes.ravel()\n",
    "\n",
    "            end_h = min(start_h + group_size, forecast_horizon)\n",
    "\n",
    "            for i, h in enumerate(range(start_h, end_h)):\n",
    "                ax = axes[i]\n",
    "                ax.plot(time_index, y_true[:, h, 0], label='Actual', color=color_actual)\n",
    "                ax.plot(time_index, y_pred[:, h, 0], label='Predicted', color=color_pred, linewidth=0.7, alpha=0.9)\n",
    "                ax.set_title(f'Forecast Horizon: t+{h + 1}', fontsize=14)\n",
    "                ax.legend(frameon=True, edgecolor='black', fontsize=10)\n",
    "                ax.grid(True, linestyle='--', alpha=0.6)\n",
    "                ax.spines['top'].set_visible(False)\n",
    "                ax.spines['right'].set_visible(False)\n",
    "                # Add y-labels to the left-side plots\n",
    "                if i % 2 == 0:\n",
    "                    ax.set_ylabel('Production')\n",
    "\n",
    "            # Hide any unused subplots in the last group\n",
    "            for i in range(end_h - start_h, group_size):\n",
    "                fig.delaxes(axes[i])\n",
    "\n",
    "            fig.text(0.5, 0.01, 'Time Steps (from start of test period)', ha='center', va='center', fontsize=14)\n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "\n",
    "            # Generate filename with letter suffix\n",
    "            suffix = chr(ord('a') + group_index)\n",
    "            output_filename = f'time_series_{prediction_method_raw}_{forecast_horizon}_{suffix}.png'\n",
    "            output_path = os.path.join('plots_for_thesis', output_filename)\n",
    "            plt.savefig(output_path)\n",
    "            print(f\"Plot saved to: {output_path}\")\n",
    "\n",
    "            #plt.show() # Show the plot for the current group\n",
    "            plt.close(fig) # Close the figure to free up memory"
   ],
   "id": "836b2dcd5740aa2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# GIF for the presentation!!!\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "\n",
    "# --- Prerequisites ---\n",
    "# This script assumes the following variables are already loaded and defined\n",
    "# in your environment before this script is run:\n",
    "#\n",
    "# y_true: A numpy array with the ground truth time series data.\n",
    "#         Shape: (num_samples, forecast_horizon, 1)\n",
    "#\n",
    "# y_pred: A numpy array with the predicted time series data.\n",
    "#         Shape: (num_samples, forecast_horizon, 1)\n",
    "#\n",
    "# time_steps: An integer representing the number of initial time steps\n",
    "#             not included in the test data.\n",
    "#\n",
    "# forecast_horizon: An integer for the number of steps to forecast.\n",
    "#\n",
    "# prediction_method: A string for the plot title (e.g., \"LSTM Model\").\n",
    "#\n",
    "# prediction_method_raw: A string for the filename (e.g., \"LSTM_Model\").\n",
    "#\n",
    "# data_loaded: A boolean flag, set to True if data is ready.\n",
    "\n",
    "# Example of how you might define these (replace with your actual data loading)\n",
    "# y_true, y_pred, time_steps, ... = load_my_data_function()\n",
    "# data_loaded = True\n",
    "\n",
    "\n",
    "# --- Plotting and GIF Generation ---\n",
    "if 'data_loaded' in locals() and data_loaded:\n",
    "    # --- Ensure required variables exist ---\n",
    "    required_vars = ['y_true', 'y_pred', 'time_steps', 'forecast_horizon', 'prediction_method', 'prediction_method_raw']\n",
    "    #if not all(var in locals() for var in required_vars):\n",
    "    #    raise NameError(\"One or more required variables (y_true, y_pred, etc.) are not defined. Please load your data first.\")\n",
    "\n",
    "    num_samples = y_true.shape[0]\n",
    "    time_index = np.arange(num_samples) + time_steps\n",
    "    color_actual = '#003366'  # Dark Blue\n",
    "    color_pred = '#CC3300'   # Dark Red\n",
    "\n",
    "    # --- Directory Setup ---\n",
    "    # Create directories to store the plots and the final GIF\n",
    "    plots_dir = 'plots_for_gif'\n",
    "    output_dir = 'plots_for_thesis'\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    image_files = []\n",
    "\n",
    "    # --- Generate Individual Plots for each Forecast Horizon ---\n",
    "    print(\"Generating individual plots for each forecast horizon...\")\n",
    "    for h in range(forecast_horizon):\n",
    "        fig, ax = plt.subplots(figsize=(14, 7), dpi=120) # Increased DPI for better quality\n",
    "        fig.patch.set_facecolor('white')\n",
    "\n",
    "        # Plot actual vs. predicted data\n",
    "        ax.plot(time_index, y_true[:, h, 0], label='Actual', color=color_actual, linewidth=2)\n",
    "        ax.plot(time_index, y_pred[:, h, 0], label='Predicted', color=color_pred, linewidth=1.5, alpha=0.9)\n",
    "\n",
    "        # --- Aesthetics and Labels ---\n",
    "        ax.set_xlabel('Time Steps', fontsize=14)\n",
    "        ax.set_ylabel('Production', fontsize=14)\n",
    "        ax.set_title(f'Time Series: Actual vs. Predicted ({prediction_method})\\nForecast Horizon: t+{h + 1}', fontsize=18)\n",
    "        ax.legend(frameon=True, edgecolor='black', fontsize=12)\n",
    "        ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "        # Improve spine visibility and ticks\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_color('grey')\n",
    "        ax.spines['bottom'].set_color('grey')\n",
    "        ax.tick_params(axis='x', colors='grey', labelsize=12)\n",
    "        ax.tick_params(axis='y', colors='grey', labelsize=12)\n",
    "\n",
    "        # Determine consistent Y-axis limits across all plots for better comparison\n",
    "        y_min = min(y_true.min(), y_pred.min())\n",
    "        y_max = max(y_true.max(), y_pred.max())\n",
    "        ax.set_ylim(y_min - 0.1 * abs(y_min), y_max + 0.1 * abs(y_max))\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the figure to a file\n",
    "        filename = f\"{plots_dir}/frame_{h:03d}.png\"\n",
    "        plt.savefig(filename)\n",
    "        image_files.append(filename)\n",
    "        plt.close(fig) # Close the figure to free up memory\n",
    "\n",
    "    print(f\"Successfully generated {len(image_files)} plot images in '{plots_dir}/'\")\n",
    "\n",
    "\n",
    "    # --- Create GIF from the saved plots ---\n",
    "    gif_path = os.path.join(output_dir, f'time_series_{prediction_method_raw}_{forecast_horizon}h_forecast.gif')\n",
    "    print(f\"Creating GIF... Saving to {gif_path}\")\n",
    "\n",
    "    with imageio.get_writer(gif_path, mode='I', duration=500, loop=0) as writer: # duration in ms\n",
    "        for filename in image_files:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "\n",
    "    print(\"GIF creation complete.\")\n",
    "\n",
    "    # --- Clean up the individual plot images ---\n",
    "    print(f\"Cleaning up temporary image files from '{plots_dir}/'...\")\n",
    "    for filename in image_files:\n",
    "        os.remove(filename)\n",
    "    os.rmdir(plots_dir)\n",
    "    print(\"Cleanup complete.\")\n",
    "\n",
    "else:\n",
    "    print(\"Data not loaded (the 'data_loaded' variable was not found or was False). Skipping plotting.\")\n",
    "\n"
   ],
   "id": "fec16ee0dee152c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.metrics import r2_score\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from src.DatabaseGetInfo import DatabaseAnalyzer\n",
    "\n",
    "# --- Cell 3: Plotting Metrics vs. Forecast Horizon ---\n",
    "\n",
    "if data_loaded:\n",
    "    # --- Get Installed Capacity using DatabaseAnalyzer ---\n",
    "    installed_capacity = None\n",
    "    try:\n",
    "        # Extract wf_id from the folder name to use in the query\n",
    "        wf_id_match = re.search(r'_wf(\\d+)_', folder_name)\n",
    "        if not wf_id_match:\n",
    "            raise ValueError(\"Could not extract wf_id from folder name.\")\n",
    "        wf_id = int(wf_id_match.group(1))\n",
    "\n",
    "        # Use the project's DatabaseAnalyzer class\n",
    "        analyzer = DatabaseAnalyzer.WindFarmAnalyzer(db_path='/home/wheatley/WFD/wfd.db')\n",
    "        moe_data = analyzer.get_moe_data(wf_id)\n",
    "\n",
    "        # Calculate installed capacity using the provided logic\n",
    "        if not moe_data.empty and 'additional_unit_power_electrical' in moe_data.columns:\n",
    "            installed_capacity = float(moe_data['additional_unit_power_electrical'].sum())\n",
    "            print(f\"Found installed capacity for wf_id {wf_id}: {installed_capacity} MW\")\n",
    "        else:\n",
    "            print(f\"Warning: No installed capacity data found via DatabaseAnalyzer for wf_id {wf_id}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during database lookup: {e}\")\n",
    "\n",
    "    # --- Calculate Metrics ---\n",
    "    r2_values, nrmse_values, nmae_values = [], [], []\n",
    "\n",
    "    if installed_capacity and installed_capacity > 0:\n",
    "        normalization_factor = installed_capacity\n",
    "        print(f\"Normalizing metrics using installed capacity: {normalization_factor} MW\")\n",
    "    else:\n",
    "        normalization_factor = np.mean(y_true)\n",
    "        if normalization_factor == 0: normalization_factor = 1\n",
    "        print(f\"Warning: Could not use installed capacity. Falling back to normalizing by the mean of y_true: {normalization_factor:.2f}\")\n",
    "\n",
    "    for h in range(forecast_horizon):\n",
    "        y_true_h, y_pred_h = y_true[:, h, 0], y_pred[:, h, 0]\n",
    "        r2 = r2_score(y_true_h, y_pred_h)\n",
    "        mae = np.mean(np.abs(y_true_h - y_pred_h))\n",
    "        rmse = np.sqrt(np.mean((y_true_h - y_pred_h)**2))\n",
    "\n",
    "        r2_values.append(r2)\n",
    "        nmae_values.append(mae / normalization_factor)\n",
    "        nrmse_values.append(rmse / normalization_factor)\n",
    "\n",
    "    # --- Create the Plot ---\n",
    "    horizons = np.arange(1, forecast_horizon + 1)\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 8), dpi=100)\n",
    "    fig.patch.set_facecolor('white')\n",
    "\n",
    "    color_nmae, color_nrmse, color_r2 = '#3399FF', '#003366', '#CC3300'\n",
    "\n",
    "    ax1.set_xlabel('Forecast Horizon (hours)', fontsize=14)\n",
    "    ax1.set_ylabel('Normalized Error (nRMSE, nMAE)', color=color_nrmse, fontsize=14)\n",
    "    # The plot calls (line1, line2, etc.) are what generate the handles and labels\n",
    "    line1 = ax1.plot(horizons, nrmse_values, marker='s', linestyle='-', color=color_nrmse, label='nRMSE')\n",
    "    line2 = ax1.plot(horizons, nmae_values, marker='^', linestyle='--', color=color_nmae, label='nMAE')\n",
    "    ax1.tick_params(axis='y', labelcolor=color_nrmse)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('R² Score', color=color_r2, fontsize=14)\n",
    "    line3 = ax2.plot(horizons, r2_values, marker='o', linestyle=':', color=color_r2, label='R²')\n",
    "    ax2.tick_params(axis='y', labelcolor=color_r2)\n",
    "\n",
    "    ax1.yaxis.set_major_locator(MaxNLocator(nbins=6, prune='both'))\n",
    "    ax2.yaxis.set_major_locator(MaxNLocator(nbins=6, prune='both'))\n",
    "    ax1.grid(True, which='major', linestyle='--', linewidth=0.5, color='gray', alpha=0.6)\n",
    "\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "\n",
    "    plt.title(f'Model Metrics vs. Forecast Horizon ({prediction_method})', fontsize=16, y=1.08)\n",
    "\n",
    "    # --- LEGEND FIX ---\n",
    "    # Get handles and labels from each axis individually\n",
    "    h1, l1 = ax1.get_legend_handles_labels()\n",
    "    h2, l2 = ax2.get_legend_handles_labels()\n",
    "\n",
    "    # Combine them into single lists\n",
    "    all_handles = h1 + h2\n",
    "    all_labels = l1 + l2\n",
    "\n",
    "    # Create the legend using the combined lists\n",
    "    ax1.legend(all_handles, all_labels, loc='lower center', bbox_to_anchor=(0.5, 1.02), ncol=3, frameon=True, edgecolor='black', fontsize=12)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.xticks(horizons)\n",
    "\n",
    "    # The 'match' object may not be defined if the discovery cell wasn't re-run, so we rebuild the method string\n",
    "    method_str_for_filename = prediction_method.replace(' ', '_').lower()\n",
    "    output_path = os.path.join('plots_for_thesis', f'metrics_vs_horizon_{method_str_for_filename}_{forecast_horizon}.png')\n",
    "    plt.savefig(output_path)\n",
    "    print(f\"Metrics plot saved to: {output_path}\")\n",
    "\n",
    "    #plt.show()\n",
    "    plt.close(fig)"
   ],
   "id": "7838548acc8df33a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This cell uses the variables loaded in the data discovery cell.\n",
    "if data_loaded:\n",
    "    # --- Configuration ---\n",
    "    num_figures_to_generate = 32\n",
    "    plots_per_figure = 4\n",
    "\n",
    "    if forecast_horizon > 3:\n",
    "        shift_amount = int(forecast_horizon / 4)\n",
    "    else:\n",
    "        shift_amount = 1\n",
    "    print(f\"Using a shift of {shift_amount} hours between subplots.\")\n",
    "\n",
    "    output_dir = os.path.join('plots_for_thesis', 'shifted_forecast_plots')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Saving up to {num_figures_to_generate} plot groups to: {output_dir}\")\n",
    "\n",
    "    # --- REVISED: Select synchronized starting points using a fixed interval ---\n",
    "    # Instead of linspace, we define a fixed interval (in hours/samples) between plot groups.\n",
    "    # This ensures that the same time windows are chosen for AR and SS models.\n",
    "    if forecast_horizon > 3:\n",
    "        fixed_interval = shift_amount*3\n",
    "    else:\n",
    "        fixed_interval = 4\n",
    "\n",
    "    # Generate a list of potential start indices\n",
    "    potential_start_indices = np.arange(1, num_figures_to_generate * fixed_interval, fixed_interval)\n",
    "\n",
    "    # Ensure the generated indices are valid for the current dataset\n",
    "    total_samples = y_true.shape[0]\n",
    "    required_span_for_group = (plots_per_figure - 1) * shift_amount\n",
    "\n",
    "    # Filter the list to only include indices that are within the bounds of our data\n",
    "    start_indices = [idx for idx in potential_start_indices if idx + required_span_for_group < total_samples]\n",
    "\n",
    "    if not start_indices:\n",
    "        print(\"Warning: Not enough data points to generate any forecast groups with the fixed intervals.\")\n",
    "    else:\n",
    "        color_actual, color_pred = '#003366', '#CC3300'\n",
    "\n",
    "        for fig_index, start_idx in enumerate(start_indices):\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(18, 12), sharex=True, sharey=True, dpi=100)\n",
    "            fig.patch.set_facecolor('white')\n",
    "            fig.suptitle(f'Forecast Examples for {prediction_method}, Starting at t={start_idx + time_steps} (from sample size)', fontsize=22, y=0.99)\n",
    "            axes = axes.ravel()\n",
    "\n",
    "            for i in range(plots_per_figure):\n",
    "                ax = axes[i]\n",
    "                current_pred_index = start_idx + (i * shift_amount)\n",
    "\n",
    "                # Get t+0 value from the previous y_true sample\n",
    "                last_known_true_value = y_true[current_pred_index - 1, 0, 0]\n",
    "\n",
    "                y_true_slice = y_true[current_pred_index, :, 0]\n",
    "                y_true_extended = np.concatenate(([last_known_true_value], y_true_slice))\n",
    "\n",
    "                y_pred_slice = y_pred[current_pred_index, :, 0]\n",
    "                y_pred_with_nan = np.concatenate(([np.nan], y_pred_slice))\n",
    "\n",
    "                horizon_axis_extended = np.arange(0, forecast_horizon + 1)\n",
    "\n",
    "                # Plot the extended data\n",
    "                ax.plot(horizon_axis_extended, y_true_extended, label='Actual', color=color_actual, marker='^', markersize=5)\n",
    "                ax.plot(horizon_axis_extended, y_pred_with_nan, label='Predicted', color=color_pred, marker='o', markersize=5, linewidth=1.2, alpha=0.9)\n",
    "\n",
    "                ax.set_title(f'Forecast Made at t={current_pred_index + time_steps}', fontsize=14)\n",
    "                ax.grid(True, linestyle='--', alpha=0.6)\n",
    "                ax.spines['top'].set_visible(False)\n",
    "                ax.spines['right'].set_visible(False)\n",
    "                ax.set_ylim(0, np.max(y_true) * 1.05)\n",
    "                ax.set_xlim(0, forecast_horizon + 1)\n",
    "\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, 0.92), ncol=2, fontsize=14, frameon=True, edgecolor='black')\n",
    "            fig.text(0.5, 0.02, 'Time Steps from Last Known Value (t+h)', ha='center', va='center', fontsize=16)\n",
    "            fig.text(0.01, 0.5, 'Production', ha='center', va='center', rotation='vertical', fontsize=16)\n",
    "            plt.tight_layout(rect=[0.03, 0.05, 1, 0.92])\n",
    "\n",
    "            output_filename = f'shifted_{prediction_method_raw}_group_{fig_index + 1}_start_t{start_idx + time_steps}.png'\n",
    "            output_path = os.path.join(output_dir, output_filename)\n",
    "            plt.savefig(output_path)\n",
    "            plt.close(fig)\n",
    "\n",
    "        print(f\"\\nFinished generating and saving {len(start_indices)} plot groups.\")"
   ],
   "id": "d6615b7180d96203",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# GIF FOR PRESENTATION\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "# --- Prerequisites ---\n",
    "# This script assumes the following variables are already loaded and defined\n",
    "# in your environment before this script is run:\n",
    "#\n",
    "# y_true: A numpy array with the ground truth time series data.\n",
    "#         Shape: (num_samples, forecast_horizon, 1)\n",
    "#         y_true[i, h, 0] is the actual value at time (i + h + time_steps).\n",
    "#\n",
    "# y_pred: A numpy array with the predicted time series data.\n",
    "#         Shape: (num_samples, forecast_horizon, 1)\n",
    "#         y_pred[i, h, 0] is the prediction for time (i + h + time_steps).\n",
    "#\n",
    "# time_steps: An integer representing the number of initial time steps\n",
    "#             not included in the test data.\n",
    "#\n",
    "# forecast_horizon: An integer for the number of steps to forecast.\n",
    "#\n",
    "# prediction_method: A string for the plot title (e.g., \"LSTM Model\").\n",
    "#\n",
    "# prediction_method_raw: A string for the filename (e.g., \"LSTM_Model\").\n",
    "#\n",
    "# data_loaded: A boolean flag, set to True if data is ready.\n",
    "\n",
    "\n",
    "# --- Plotting and GIF Generation ---\n",
    "if 'data_loaded' in locals() and data_loaded:\n",
    "    # --- Ensure required variables exist ---\n",
    "    required_vars = ['y_true', 'y_pred', 'time_steps', 'forecast_horizon', 'prediction_method', 'prediction_method_raw']\n",
    "    #if not all(var in locals() for var in required_vars):\n",
    "     #   raise NameError(\"One or more required variables (y_true, y_pred, etc.) are not defined. Please load your data first.\")\n",
    "\n",
    "    num_samples = y_true.shape[0]\n",
    "\n",
    "    # This is the x-axis for the start of each forecast\n",
    "    time_index = np.arange(num_samples) + time_steps\n",
    "\n",
    "    color_history = '#003366'  # Dark Blue\n",
    "    color_forecast = '#CC3300'   # Dark Red\n",
    "    color_future_true = '#006633' # Dark Green\n",
    "\n",
    "    # --- Directory Setup ---\n",
    "    plots_dir = 'plots_for_rolling_gif'\n",
    "    output_dir = 'plots_for_thesis'\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    image_files = []\n",
    "\n",
    "    # --- Set consistent plot limits for a smooth animation ---\n",
    "    y_min = min(y_true.min(), y_pred.min())\n",
    "    y_max = max(y_true.max(), y_pred.max())\n",
    "    y_padding = 0.1 * (y_max - y_min)\n",
    "    plot_ylim = (y_min - y_padding, y_max + y_padding)\n",
    "\n",
    "    # X-axis will go from the start of the data to the end of the last possible forecast\n",
    "    plot_xlim = (time_index[0], time_index[-1] + forecast_horizon)\n",
    "\n",
    "    # --- Generate Individual Plots for each Time Step ---\n",
    "    print(f\"Generating {num_samples} individual plots for the rolling forecast animation...\")\n",
    "\n",
    "    # We loop through each point in time where a forecast was made\n",
    "    for i in range(num_samples):\n",
    "        # Stop before the end if we don't have enough future data to plot against the forecast\n",
    "        if i + forecast_horizon > num_samples:\n",
    "            break\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(14, 7), dpi=100) # dpi=100 for faster generation\n",
    "        fig.patch.set_facecolor('white')\n",
    "\n",
    "        # --- 1. Plot Historical Data ---\n",
    "        # The history is all true values up to the point of forecast (using the t+1 truth)\n",
    "        historical_x = time_index[:i+1]\n",
    "        historical_y = y_true[:i+1, 0, 0] # Using h=0 as the \"true\" line\n",
    "        ax.plot(historical_x, historical_y, label='Historical Production', color=color_history, linewidth=2)\n",
    "\n",
    "        # --- 2. Plot the Forecast ---\n",
    "        forecast_x = time_index[i] + np.arange(forecast_horizon)\n",
    "        forecast_y = y_pred[i, :, 0]\n",
    "        ax.plot(forecast_x, forecast_y, label='Forecast', color=color_forecast, linewidth=2, linestyle='--')\n",
    "\n",
    "        # --- 3. Plot the Future Ground Truth for comparison ---\n",
    "        # The actual values that the forecast was trying to predict\n",
    "        future_true_y = []\n",
    "        for h in range(forecast_horizon):\n",
    "            future_true_y.append(y_true[i + h, 0, 0]) # The t+1 truth at future points\n",
    "\n",
    "        # A more direct way using the data structure: y_true[i,:,0] are the true values for the forecast from i\n",
    "        future_true_y = y_true[i, :, 0]\n",
    "\n",
    "        ax.plot(forecast_x, future_true_y, label='Future Actual', color=color_future_true, linewidth=2, linestyle=':')\n",
    "\n",
    "        # --- 4. Add a vertical line to show the \"present\" ---\n",
    "        ax.axvline(x=time_index[i], color='grey', linestyle='--', linewidth=1.5, label=f'Forecast Point (t={time_index[i]})')\n",
    "\n",
    "        # --- Aesthetics and Labels ---\n",
    "        ax.set_xlabel('Time Steps', fontsize=14)\n",
    "        ax.set_ylabel('Production', fontsize=14)\n",
    "        ax.set_title(f'Rolling Forecast Animation ({prediction_method})', fontsize=18)\n",
    "        ax.legend(frameon=True, edgecolor='black', fontsize=10, loc='upper left')\n",
    "        ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "        ax.set_ylim(plot_ylim)\n",
    "        ax.set_xlim(plot_xlim)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the figure to a file\n",
    "        filename = f\"{plots_dir}/frame_{i:04d}.png\" # Use 4 digits for potentially many frames\n",
    "        plt.savefig(filename)\n",
    "        image_files.append(filename)\n",
    "        plt.close(fig) # Close the figure to free up memory\n",
    "\n",
    "    print(f\"Successfully generated {len(image_files)} plot images in '{plots_dir}/'\")\n",
    "\n",
    "    # --- Create GIF from the saved plots ---\n",
    "    gif_path = os.path.join(output_dir, f'rolling_forecast_{prediction_method_raw}.gif')\n",
    "    print(f\"Creating GIF... Saving to {gif_path}\")\n",
    "\n",
    "    # Duration is now 100ms for a faster pace (10 FPS)\n",
    "    with imageio.get_writer(gif_path, mode='I', duration=100, loop=0) as writer:\n",
    "        for filename in image_files:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "\n",
    "    print(\"GIF creation complete.\")\n",
    "\n",
    "    # --- Clean up the individual plot images ---\n",
    "    print(f\"Cleaning up temporary image files from '{plots_dir}/'...\")\n",
    "    for filename in image_files:\n",
    "        os.remove(filename)\n",
    "    os.rmdir(plots_dir)\n",
    "    print(\"Cleanup complete.\")\n",
    "\n",
    "else:\n",
    "    print(\"Data not loaded (the 'data_loaded' variable was not found or was False). Skipping plotting.\")\n"
   ],
   "id": "745d9128128f19d8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
